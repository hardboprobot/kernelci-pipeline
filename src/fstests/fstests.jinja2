{# -*- mode: Python -*- -#}
{# SPDX-License-Identifier: LGPL-2.1-or-later -#}

{%- extends 'base/python.jinja2' %}

{%- block python_globals %}
{{ super() }}
GCE               = '{{True if gce is not none else NONE}}'
GCE_PROJECT       = '{{gce_project if gce_project is not none else NONE}}'
GCE_ZONE          = '{{gce_zone if gce_zone is not none else NONE}}'
GS_BUCKET         = '{{gs_bucket if gs_bucket is not none else NONE}}'
# TBD: For production, set the appropriate njobs number by default
NJOBS             = '{{njobs if njobs is not none else 1}}'
OUTPUT            = '{{output if output is not none else NONE}}'
SKIP_BUILD        = '{{True if skip_build is not none else NONE}}'
TESTCASE          = '{{testcase if testcase is not none else NONE}}'
TESTCFG           = '{{testcfg if testcfg is not none else NONE}}'
TESTGROUP         = '{{testgroup if testgroup is not none else NONE}}'
XFSTESTS_BLD_PATH = '{{xfstests_bld_path}}'
{% endblock %}

{%- block python_imports %}
{{ super() }}
import json
import os
import shutil
import subprocess
import xml.etree.ElementTree as ET
import re
import traceback
import time
import glob
from abc import ABC, abstractmethod
{%- endblock %}

{% block python_job -%}

class Xfstests(ABC):
    """Base class (abstract) to handle the setup, running and collection of
    results for xfstests.
    """

    # xfstests fs configs
    configs = ['4k',           '1k',       'ext3',        'encrypt',
               'nojournal',    'ext3conv', 'adv',         'dioread_nolock',
               'data_journal', 'bigalloc', 'bigalloc_1k',
    ]

    def kernel_config(self, kdir):
        """Uses the kvm-xfstests script to configure a kernel for xfstests. The
        kernel source must be already decompressed in KDIR.

        Args:
            kdir (str): base directory of the kernel source

        Returns:
            bool: True for success, False otherwise
        """
        try:
            os.chdir(kdir)
            result = subprocess.run('kvm-xfstests install-kconfig',
                                    check=True, shell=True)
            print(f"Kernel config done.")
            return True
        except Exception as e:
            print("Kernel config error:", e)
            return False

    def kernel_build(self, kdir, njobs=1):
        """Builds an already configured Linux kernel.

        Args:
            kdir (str): base directory of the kernel source
            njobs (int, optional): number of parallel build jobs
        """
        try:
            os.chdir(kdir)
            result = subprocess.run(f'make -j{njobs}', check=True, shell=True)
            print(f"Kernel Build DONE.")
            return True
        except Exception as e:
            print("Kernel build error:", e)
            return False

    def _parse_xml_test_results(self, f, tree):
        """Parses the xfstests XML-formatted test results into an in-memory
        tree (dict).

        Args:
            f (str): path of the XML file to parse
            tree (dict): dict to save the data to. It may be populated
                already.

        Returns:
            A dict containing the result tree.
        """
        xml_file = ET.parse(f)
        root = xml_file.getroot()

        # Parse the test config: filesystem type and config, create the
        # initial tree nodes for them if they don't exist yet
        testcfg = root.find('properties/property[@name="TESTCFG"]').attrib['value']
        fs, cfg = testcfg.split('/')
        if fs in tree:
            if cfg not in tree[fs]:
                tree[fs][cfg] = {}
        else:
            tree[fs] = {cfg: {}}

        # Parse the test results
        for test_case in root.iter('testcase'):
            if test_case.find('skipped') is not None:
                result = 'skipped'
            elif test_case.find('failure') is not None:
                result = 'fail'
            else:
                result = 'pass'
            suite, test = test_case.attrib['name'].split('/')
            if not suite in tree[fs][cfg]:
                tree[fs][cfg][suite] = {}
            tree[fs][cfg][suite][test] = {
                'result'   : result,
                # Save the path of the original XML results file as test
                # artifacts
                'artifacts': {'log': f},
            }
        return tree

    def _convert_results_for_api(self, tree, name):
        """Takes a tree containing the xfstests results and formats it as
        KernelCI-API nodes.

        Args:
            tree (dict): xfstests results
            name (str): name of the result root node

        Returns:
            A dict containing the KernelCI API nodes ready to be
            submitted.
        """
        if 'result' in tree:
            return {
                'node': {
                    'name': name,
                    'result': tree['result'],
                    'artifacts': tree.get('artifacts'),
                },
                'child_nodes':[]
            }
        else:
            child_nodes = []
            for child_name in tree:
                child_nodes.append(
                    self._convert_results_for_api(tree[child_name], child_name))
            return {
                'node':{
                    'name': name,
                },
                'child_nodes': child_nodes,
            }

    def parse_results(self, path):
        """Parses and processes the test result files in PATH.

        Args:
            path (str): Directory to look for XML-formatted result files

        Returns:
            A dict containing the test results formatted according to the
            KernelCI-API.
        """
        # Parse the test results
        test_results = {}
        for xmlfile in glob.glob(os.path.join(path, 'results-*.xml')):
            test_results = self._parse_xml_test_results(xmlfile, test_results)

        # Turn them into KernelCI-API data
        api_data = self._convert_results_for_api(test_results, 'fstests')
        return api_data

    @abstractmethod
    def run(self, kdir, testcase='', group=False, testcfg=''):
        """Runs the specified xfstests testcase using the kernel built in KDIR.

        Args:
            kdir (str): directory containing a built Linux kernel
            testcase (str): xfstests to run (single test or
                comma-separated list)
            group (bool): true if the testcase argument refers to a test group
            testcfg (str): xfstests config to run (single config or
                comma-separated list)

        Returns:
            bool: True for success, False otherwise
        """
        pass

    @abstractmethod
    def get_xml_results(self, path):
        """Extracts the XML-formatted test results and stores them in PATH.

        Args:
            path (str): Directory where to copy the XML results file.

        Returns:
                bool: True for success, False otherwise
        """
        pass


class KvmXfstests(Xfstests):
    def _results_cleanup(self):
        """Removes all the results.xml files from the results virtual disk
           (vdg).
        """
        for c in KvmXfstests.configs:
            subprocess.run((f'debugfs -wR "rm ext4/results-{c}/results.xml" '
                            f'{XFSTESTS_BLD_PATH}/run-fstests/disks/vdg'),
                           shell=True,
                           check=True,
                           capture_output=True)

    def run(self, kdir, testcase='', group=False, testcfg=''):
        cmd = ['kvm-xfstests']
        if testcfg:
            cmd.extend(['-c', testcfg])
        if group:
            cmd.extend(['-g', testcase])
        else:
            cmd.append(testcase)
        try:
            os.chdir(kdir)
        except FileNotFoundError:
            print(f"Kernel directory not found: {kdir}")
            return False
        try:
            self._results_cleanup()
            result = subprocess.run(cmd, check=True)
            print(f"Test run success.")
            return True
        except Exception as e:
            print("Problem found during tests:", e)
            return False

    def get_xml_results(self, path):
        try:
            for c in KvmXfstests.configs:
                result = subprocess.run(
                    (f'debugfs -R "dump ext4/results-{c}/results.xml '
                     f'{path}/results-{c}.xml" {XFSTESTS_BLD_PATH}/run-fstests/disks/vdg'),
                    shell=True,
                    check=True,
                    capture_output=True)
            return True
        except Exception as e:
            # TBD: proper error handling
            traceback.print_exc()
            return False


class GceXfstests(Xfstests):
    def __init__(self):
        self.vm_id = ''
        self.results_tarball = ''
        self.gce_env = os.environ.copy()
        if GCE_PROJECT:
            self.gce_env['GCE_PROJECT'] = GCE_PROJECT
        if GCE_ZONE:
            self.gce_env['GCE_ZONE'] = GCE_ZONE
        if GS_BUCKET:
            self.gce_env['GS_BUCKET'] = GS_BUCKET

    def _wait_for_completion(self, vm_id):
        """Checks the existence of a test result tarball for VM_ID in the Google
        Storage bucket specified in the GS_BUCKET parameter. This method
        blocks until the result is generated or until a
        KeyboardInterrupt is received.  """
        poll_period = 10        # seconds
        m = re.search("-(\d{14})", vm_id)
        tstamp = m.group(1)
        try:
            while True:
                result = subprocess.run(
                    ['gsutil', 'ls',
                     f"gs://{self.gce_env['GS_BUCKET']}/results/results.*-{tstamp}.*"],
                    capture_output=True,
                    encoding='utf-8')
                if result.returncode == 0:
                    return result.stdout
                time.sleep(poll_period)
        except KeyboardInterrupt:
            return None

    def run(self, kdir, testcase='', group=False, testcfg=''):
        # Currently uses gce-xfstests to run a single VM
        # TBD: Either use gce-xfstests LTM or use gcloud directly and
        # manage the concurrent VMs ourselves
        cmd = ['gce-xfstests']
        if testcfg:
            cmd.extend(['-c', testcfg])
        if group:
            cmd.extend(['-g', testcase])
        else:
            cmd.append(testcase)
        try:
            os.chdir(kdir)
        except FileNotFoundError:
            print(f"Kernel directory not found: {kdir}")
            return False
        try:
            result = subprocess.run(cmd, check=True,
                                    env=self.gce_env,
                                    capture_output=True, encoding='utf-8')
            m = re.search("Launching ([a-zA-Z0-9\-]+) ", result.stdout)
            if not m:
                print("Error creating the VM or retrieving the ID.",
                      f"output: {result.stdout}")
                return False
            self.vm_id = m.group(1)
            print(f"Test started in VM {self.vm_id}. Waiting for it to finish")
            self.results_tarball = self._wait_for_completion(self.vm_id)
            return True if self.results_tarball else False
        except FileNotFoundError:
            print("Can't find the gce-xfstests script, check $PATH")
            return False
        except subprocess.CalledProcessError as e:
            print("Error running gce-xfstests:", e.stdout)
            return False
        except Exception:
            traceback.print_exc()
            return False

    def get_xml_results(self, path):
        try:
            result = subprocess.run(
                ['gce-xfstests', 'get-results', '--unpack',
                 os.path.basename(self.results_tarball)],
                check=True, env=self.gce_env,
                capture_output=True, encoding='utf-8')
            m = re.match("Unpacked results at (.+)$", result.stdout)
        except subprocess.CalledProcessError as e:
            print("Error running gce-xfstests get-results:", e.stdout)
            return False
        except Exception:
            traceback.print_exc()
            return False
        for c in GceXfstests.configs:
            result_file = os.path.join(m.group(1), 'ext4',
                                       f'results-{c}', 'results.xml')
            # Will most likely throw a few FileNotFoundError's
            try:
                shutil.copy(result_file, os.path.join(path, f'results-{c}.xml'))
            except FileNotFoundError:
                continue
        print(f"XML files extracted to {path}")
        return True


class Job(BaseJob):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        if os.path.exists(self._workspace):
            shutil.rmtree(self._workspace)

    # TBD: Implement
    def _check_parameters(self):
        if TESTCASE and TESTGROUP:
            print("Error, can't specify both the testcase and the testgroup.")
            return False
        if not TESTCASE and not TESTGROUP:
            print("Error, no testcase or testgroup specified.")
            return False
        return True

    def _run(self, src_path):
        fail_results = {
            'node': {
                'name': 'fstests',
                'result': 'fail',
                'state': 'done',
            },
            'child_nodes':[],
        }
        if not self._check_parameters():
             return fail_results

        if GCE:
            test = GceXfstests()
        else:
            test = KvmXfstests()

        # Config and build kernel
        if not SKIP_BUILD:
            if not test.kernel_config(src_path):
                return fail_results
            if not test.kernel_build(src_path, NJOBS):
                return fail_results
        if TESTGROUP:
            test_ok = test.run(src_path, TESTGROUP, True, TESTCFG)
        else:
            test_ok = test.run(src_path, TESTCASE, False, TESTCFG)
        if not test_ok:
            return fail_results

        # TBD: If no output dir is specified, use the kernel src dir to
        # store the test artifacts. Find a better default solution
        if OUTPUT:
            output = OUTPUT
        else:
            output = src_path
        if not test.get_xml_results(output):
            return fail_results
        try:
            results = test.parse_results(output)
            # TBD: What does 'pass' mean in the root node?
            results['node']['result'] = 'pass'
            results['node']['state'] = 'done'
            with open(os.path.join(output, 'results.json'), 'w') as result_file:
                result_file.write(json.dumps(results))
        except Exception as e:
            traceback.print_exc()
            return fail_results
        return results

    def _submit(self, results, node_id, db):
        node = db.get_node(node_id)
        db.submit_results(results, node)
        print(f"Result node submitted: {node_id}")
        return node
{% endblock %}
